
const std::map<TokenType, std::string> Lexer::tokentype_names = {
  { TokenType:: UNDEF, "undef" },
  { TokenType:: NAME, "name" },
  { TokenType:: CONST, "string" },
  { TokenType:: NUMBER, "number" },
  { TokenType:: OPERATOR,"operator" },
  { TokenType:: SCHAR, "sp_char" },
  { TokenType:: COMMENT, "comment" },
  { TokenType:: SPACE, "space" },
  { TokenType:: BLOCK, "block" },
  { TokenType:: END_OF_FILE, "endoffile" }
};

// Lexer 클래스 멤버 변수 초기화
const std::unordered_map<std::string, TokenSubtype> Lexer::keywords = {
  {"if", TokenSubtype::KEYWORD},
  {"else", TokenSubtype::KEYWORD},
  {"do", TokenSubtype::KEYWORD},
  {"while", TokenSubtype::KEYWORD},
  {"for", TokenSubtype::KEYWORD},
  {"switch", TokenSubtype::KEYWORD},
  {"case", TokenSubtype::KEYWORD},
  {"break", TokenSubtype::KEYWORD},
  {"default", TokenSubtype::KEYWORD},
  {"auto", TokenSubtype::KEYWORD},
  {"def", TokenSubtype::KEYWORD},
  {"try", TokenSubtype::KEYWORD},
  {"catch", TokenSubtype::KEYWORD},
  {"throw", TokenSubtype::KEYWORD},
  {"function", TokenSubtype::KEYWORD},

  {"include", TokenSubtype::PREKEY},
  {"define", TokenSubtype::PREKEY},
  {"undef", TokenSubtype::PREKEY},
  {"ifdef", TokenSubtype::PREKEY},
  {"endif", TokenSubtype::PREKEY},

  {"void", TokenSubtype::DATTYPE},
  {"char", TokenSubtype::DATTYPE},
  {"unsigned", TokenSubtype::DATTYPE},
  {"int", TokenSubtype::DATTYPE},
  {"long", TokenSubtype::DATTYPE},
  {"float", TokenSubtype::DATTYPE},
  {"double", TokenSubtype::DATTYPE},
  {"bool", TokenSubtype::DATTYPE},

  {"true", TokenSubtype::DATTYPE},
  {"false", TokenSubtype::DATTYPE},

  {"struct", TokenSubtype::DATTYPE},
  {"class", TokenSubtype::DATTYPE},
  {"enum", TokenSubtype::DATTYPE},
  {"typedef", TokenSubtype::DATTYPE},

  {"const", TokenSubtype::DATTYPE},
  {"static", TokenSubtype::DATTYPE},
  {"namespace", TokenSubtype::DATTYPE},
  {"extern", TokenSubtype::DATTYPE},
  {"inline", TokenSubtype::DATTYPE},
  
  {"private", TokenSubtype::DATTYPE},
  {"protected", TokenSubtype::DATTYPE},
  {"public", TokenSubtype::DATTYPE},

  {"return", TokenSubtype::KEYWORD} // 예시에 return 추가
};

/*
python

b = --copy/paste-- TokenSubtype split('\n')

for l in b:
  r=l.split(',')[0].strip()
  if len(r) == 0: continue
  u = r.lower()
  print( "\t{ TokenSubtype::" + r + f", \"{u}\"" +" }," ) 
*/

const std::map<TokenSubtype, std::string> Lexer::tokenSubtype_names = {
	{ TokenSubtype::UNDEF, "undef" },
	{ TokenSubtype::NAME, "name" },
	{ TokenSubtype::KEYWORD, "keyword" },
	{ TokenSubtype::IDENTIFIER, "identifier" },
	{ TokenSubtype::DATTYPE, "dattype" },
	{ TokenSubtype::PREKEY, "prekey" },
	{ TokenSubtype::CONST, "const" },
	{ TokenSubtype::STRING_LITERAL, "string_literal" },
	{ TokenSubtype::NUMBER, "number" },
	{ TokenSubtype::INTEGER, "integer" },
	{ TokenSubtype::FLOAT, "float" },
	{ TokenSubtype::BIN_NUM, "bin_num" },
	{ TokenSubtype::OCT_NUM, "oct_num" },
	{ TokenSubtype::HEX_NUM, "hex_num" },
	{ TokenSubtype::OPERATOR, "operator" },
	{ TokenSubtype::ARTHMETIC_OP, "arthmetic_op" },
	{ TokenSubtype::ASSIGN_OP, "assign_op" },
	{ TokenSubtype::SIGN_OP, "sign_op" },
	{ TokenSubtype::INCRE_OP, "incre_op" },
	{ TokenSubtype::RELATIVE_OP, "relation_op" },
	{ TokenSubtype::LOGIC_OP, "logic_op" },
	{ TokenSubtype::BITWISE_OP, "bitwise_op" },
	{ TokenSubtype::STRUCT_OP, "struct_op" },
	{ TokenSubtype::SCOPE_OP, "scope_op" },
	{ TokenSubtype::UNARY_OP, "unary_op" },
	{ TokenSubtype::ETC_OP, "etc_op" },
	{ TokenSubtype::SCHAR, "schar" },
	{ TokenSubtype::SPACE, "space" },
	{ TokenSubtype::COMMENT, "comment" },
	{ TokenSubtype::LINE_COMMENT, "line_comment" },
	{ TokenSubtype::BLOCK_COMMENT, "block_comment" },
	{ TokenSubtype::BLOCK, "block" },
	{ TokenSubtype::PAREN_OPEN, "paren_open" },
	{ TokenSubtype::PAREN_CLOSE, "paren_close" },
	{ TokenSubtype::BRACE_OPEN, "brace_open" },
	{ TokenSubtype::BRACE_CLOSE, "brace_close" },
	{ TokenSubtype::SQUARE_BRACKET_OPEN, "square_bracket_open" },
	{ TokenSubtype::SQUARE_BRACKET_CLOSE, "square_bracket_close" },
	{ TokenSubtype::ANGLE_BRACKET_OPEN, "angle_bracket_open" },
	{ TokenSubtype::ANGLE_BRACKET_CLOSE, "angle_bracket_close" },
	{ TokenSubtype::END_OF_FILE,"end_of_file"}  // EOF, "end_of_file = -1  // eof" },
};

const std::map<std::string, TokenSubtype, std::greater<> > Lexer::operators_subtype = {
  { "<<=", TokenSubtype::BITWISE_OP },
  { ">>=", TokenSubtype::BITWISE_OP },
  { "==",  TokenSubtype::RELATIVE_OP },
  { ">=",  TokenSubtype::RELATIVE_OP },
  { "<=",  TokenSubtype::RELATIVE_OP },
  { "!=",  TokenSubtype::RELATIVE_OP },
  { "||",  TokenSubtype::LOGIC_OP },
  { "&&",  TokenSubtype::LOGIC_OP },
  { "++",  TokenSubtype::INCRE_OP },
  { "--",  TokenSubtype::INCRE_OP },
  { "::",  TokenSubtype::SCOPE_OP },
  { "+=",  TokenSubtype::ASSIGN_OP },
  { "-=",  TokenSubtype::ASSIGN_OP },
  { "*=",  TokenSubtype::ASSIGN_OP },
  { "/=",  TokenSubtype::ASSIGN_OP },
  { "%=",  TokenSubtype::ARTHMETIC_OP },
  { "|=",  TokenSubtype::BITWISE_OP },
  { "&=",  TokenSubtype::BITWISE_OP },
  { "^=",  TokenSubtype::BITWISE_OP },
  { "->",  TokenSubtype::STRUCT_OP },
  { ">>",  TokenSubtype::SHIFT_OP },
  { "<<",  TokenSubtype::SHIFT_OP },
  { "+",   TokenSubtype::ARTHMETIC_OP },
  { "-",   TokenSubtype::ARTHMETIC_OP },
  { "*",   TokenSubtype::ARTHMETIC_OP },
  { "/",   TokenSubtype::ARTHMETIC_OP },
  { "%",   TokenSubtype::ARTHMETIC_OP },
  { "!",   TokenSubtype::LOGIC_OP },
  { ".",   TokenSubtype::STRUCT_OP },
  { "=",   TokenSubtype::ASSIGN_OP },
  { ">",   TokenSubtype::RELATIVE_OP },
  { "<",   TokenSubtype::RELATIVE_OP },
  { "|",   TokenSubtype::BITWISE_OP },
  { "&",   TokenSubtype::BITWISE_OP },
  { "^",   TokenSubtype::BITWISE_OP },
  { "?",   TokenSubtype::LOGIC_OP },
  { "~",   TokenSubtype::UNARY_OP },
//  { "+",   TokenSubtype::UNARY_OP },
//  { "-",   TokenSubtype::UNARY_OP },
  { "", TokenSubtype::END_OF_FILE }
};

const char *_comment_line_strs[] =  { "//", NULL };
const char *_comment_block_strs[] =  { "/*", "*/", NULL };
const char __operator_chars[] = "+-*/%!~^|&=<>:?~.";


